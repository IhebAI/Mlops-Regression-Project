{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.409701300Z",
     "start_time": "2024-06-27T06:22:22.395919400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.409701300Z",
     "start_time": "2024-06-27T06:22:22.400607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\iheba\\\\IdeaProjects\\\\Mlops-Regression-Project\\\\research'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.416701300Z",
     "start_time": "2024-06-27T06:22:22.408699900Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.434656Z",
     "start_time": "2024-06-27T06:22:22.416701300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\iheba\\\\IdeaProjects\\\\Mlops-Regression-Project'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.477278700Z",
     "start_time": "2024-06-27T06:22:22.425655500Z"
    }
   },
   "outputs": [],
   "source": [
    "from box import ConfigBox\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    model_name: str\n",
    "    trained_model_file_path: Path\n",
    "    grid_search_evaluation_result: Path\n",
    "    transformed_train_data_path: Path\n",
    "    transformed_test_data_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.578382700Z",
     "start_time": "2024-06-27T06:22:22.468279300Z"
    }
   },
   "outputs": [],
   "source": [
    "from RegressionProject.utils.common import read_yaml, create_directories, save_object_pkl, save_json\n",
    "from RegressionProject.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:22:22.583597Z",
     "start_time": "2024-06-27T06:22:22.579383Z"
    }
   },
   "outputs": [],
   "source": [
    "from RegressionProject.constants import *\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH,\n",
    "            schema_filepath=SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        data_transformation_config = self.config.data_transformation\n",
    "        train_config = self.config.model_trainer\n",
    "\n",
    "        create_directories([train_config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=train_config.root_dir,\n",
    "            model_name=train_config.model_name,\n",
    "            trained_model_file_path=train_config.trained_model_file_path,\n",
    "            grid_search_evaluation_result=train_config.grid_search_evaluation_result,\n",
    "            transformed_train_data_path=data_transformation_config.transformed_data_train,\n",
    "            transformed_test_data_path=data_transformation_config.transformed_data_test\n",
    "\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T06:33:48.713248300Z",
     "start_time": "2024-06-27T06:33:48.702073500Z"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from RegressionProject.logging import logger\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from RegressionProject.utils.common import read_yaml, create_directories, load_json\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def prepare_params_models_gs(self, params):\n",
    "        model_params = {\n",
    "            'Decision Tree': (DecisionTreeRegressor(), params.Decision_Tree.to_dict()),\n",
    "            'Random Forest': (RandomForestRegressor(), params.Random_Forest.to_dict()),\n",
    "            'Gradient Boosting': (GradientBoostingRegressor(), params.Gradient_Boosting.to_dict()),\n",
    "            'Linear Regression': (LinearRegression(), {}),\n",
    "            'XGBRegressor': (XGBRegressor(), params.XGBRegressor.to_dict()),\n",
    "            'CatBoosting Regressor': (CatBoostRegressor(verbose=False), params.CatBoosting_Regressor.to_dict()),\n",
    "            'AdaBoost Regressor': (AdaBoostRegressor(), params.AdaBoost_Regressor.to_dict()),\n",
    "        }\n",
    "        return model_params\n",
    "\n",
    "    def perform_grid_search(self, model, param_grid, X, y):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X, y)\n",
    "        logger.info(f\"Best params for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
    "        logger.info(f\"Best score for {model.__class__.__name__}: {grid_search.best_score_}\")\n",
    "        return grid_search\n",
    "\n",
    "    def evaluate_models(self, x_train, y_train, x_test, y_test, model_params):\n",
    "        results = {}\n",
    "        for model_name, (model, param_grid) in model_params.items():\n",
    "            logger.info(f\"Performing grid search for {model_name}\")\n",
    "            grid_search = self.perform_grid_search(model, param_grid, x_train, y_train)\n",
    "\n",
    "            best_params = grid_search.best_params_\n",
    "            model.set_params(**best_params)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            y_train_pred = model.predict(x_train)\n",
    "            y_test_pred = model.predict(x_test)\n",
    "\n",
    "            # Calculate training and test metrics\n",
    "            train_model_score = r2_score(y_train, y_train_pred)\n",
    "            test_model_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "            results[model_name] = {\n",
    "                'best_params': best_params,\n",
    "                'model': model,\n",
    "                'train_model_score': train_model_score,\n",
    "                'test_model_score': test_model_score\n",
    "            }\n",
    "            # Export results to JSON\n",
    "        save_json(Path(self.config.grid_search_evaluation_result), results)\n",
    "        logger.info(f\"Training results after grid search is exported to {self.config.grid_search_evaluation_result} \")\n",
    "\n",
    "    def read_transformed_data(self, transformed_train_data_path, transformed_test_data_path):\n",
    "        train_data = pd.read_csv(transformed_train_data_path)\n",
    "        test_data = pd.read_csv(transformed_test_data_path)\n",
    "        target_column = train_data.columns[-1]\n",
    "        train_x = train_data.drop([target_column], axis=1)\n",
    "        test_x = test_data.drop([target_column], axis=1)\n",
    "        train_y = train_data[target_column].values\n",
    "        test_y = test_data[target_column].values\n",
    "        return train_x, train_y, test_x, test_y\n",
    "\n",
    "    def models_trainer(self, params, transformed_train_data_path, transformed_test_data_path):\n",
    "        train_x, train_y, test_x, test_y = self.read_transformed_data(transformed_train_data_path,\n",
    "                                                                      transformed_test_data_path)\n",
    "        model_params = self.prepare_params_models_gs(params)\n",
    "        self.evaluate_models(train_x, train_y, test_x, test_y, model_params)\n",
    "        results = load_json(Path(self.config.grid_search_evaluation_result))\n",
    "        best_model_name = max(results, key=lambda x: results[x]['test_model_score'])\n",
    "        best_model = results[best_model_name]['model']\n",
    "        logger.info(\"Best Model found is : {}\".format(best_model))\n",
    "        save_object_pkl(Path(self.config.trained_model_file_path), best_model, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-26 23:33:49,151: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-06-26 23:33:49,155: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-06-26 23:33:49,156: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2024-06-26 23:33:49,157: INFO: common: created directory at: artifacts]\n",
      "[2024-06-26 23:33:49,158: INFO: common: created directory at: artifacts/model_trainer]\n",
      "{'Decision Tree': (DecisionTreeRegressor(), {'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson']}), 'Random Forest': (RandomForestRegressor(), {'n_estimators': [8, 16, 32, 64, 128, 256]}), 'Gradient Boosting': (GradientBoostingRegressor(), {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9], 'n_estimators': [8, 16, 32, 64, 128, 256]}), 'Linear Regression': (LinearRegression(), {}), 'XGBRegressor': (XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...), {'learning_rate': [0.1, 0.01, 0.05, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]}), 'CatBoosting Regressor': (<catboost.core.CatBoostRegressor object at 0x000001F65697BF10>, {'depth': [6, 8, 10], 'learning_rate': [0.01, 0.05, 0.1], 'iterations': [30, 50, 100]}), 'AdaBoost Regressor': (AdaBoostRegressor(), {'learning_rate': [0.1, 0.01, 0.5, 0.001], 'n_estimators': [8, 16, 32, 64, 128, 256]})}\n",
      "[2024-06-26 23:33:49,169: INFO: 378739507: Performing grid search for Decision Tree]\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[2024-06-26 23:33:52,497: INFO: 378739507: Best params for DecisionTreeRegressor: {'criterion': 'friedman_mse'}]\n",
      "[2024-06-26 23:33:52,497: INFO: 378739507: Best score for DecisionTreeRegressor: 0.7015955676758344]\n",
      "[2024-06-26 23:33:52,504: INFO: 378739507: Performing grid search for Random Forest]\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[2024-06-26 23:33:54,055: INFO: 378739507: Best params for RandomForestRegressor: {'n_estimators': 256}]\n",
      "[2024-06-26 23:33:54,055: INFO: 378739507: Best score for RandomForestRegressor: 0.8333088570448413]\n",
      "[2024-06-26 23:33:54,647: INFO: 378739507: Performing grid search for Gradient Boosting]\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[2024-06-26 23:34:00,121: INFO: 378739507: Best params for GradientBoostingRegressor: {'learning_rate': 0.05, 'n_estimators': 128, 'subsample': 0.7}]\n",
      "[2024-06-26 23:34:00,121: INFO: 378739507: Best score for GradientBoostingRegressor: 0.853870705159328]\n",
      "[2024-06-26 23:34:00,218: INFO: 378739507: Performing grid search for Linear Regression]\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[2024-06-26 23:34:00,237: INFO: 378739507: Best params for LinearRegression: {}]\n",
      "[2024-06-26 23:34:00,237: INFO: 378739507: Best score for LinearRegression: 0.8678130154302321]\n",
      "[2024-06-26 23:34:00,246: INFO: 378739507: Performing grid search for XGBRegressor]\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[2024-06-26 23:34:02,202: INFO: 378739507: Best params for XGBRegressor: {'learning_rate': 0.1, 'n_estimators': 32}]\n",
      "[2024-06-26 23:34:02,203: INFO: 378739507: Best score for XGBRegressor: 0.8323733240716148]\n",
      "[2024-06-26 23:34:02,262: INFO: 378739507: Performing grid search for CatBoosting Regressor]\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[2024-06-26 23:34:07,965: INFO: 378739507: Best params for CatBoostRegressor: {'depth': 6, 'iterations': 100, 'learning_rate': 0.1}]\n",
      "[2024-06-26 23:34:07,966: INFO: 378739507: Best score for CatBoostRegressor: 0.8511799032553032]\n",
      "[2024-06-26 23:34:08,083: INFO: 378739507: Performing grid search for AdaBoost Regressor]\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[2024-06-26 23:34:10,325: INFO: 378739507: Best params for AdaBoostRegressor: {'learning_rate': 0.5, 'n_estimators': 256}]\n",
      "[2024-06-26 23:34:10,325: INFO: 378739507: Best score for AdaBoostRegressor: 0.8253544939765028]\n",
      "[2024-06-26 23:34:10,620: INFO: common: json file saved at: artifacts\\model_trainer\\train_results.json]\n",
      "[2024-06-26 23:34:10,621: INFO: 378739507: Training results after grid search is exported to artifacts/model_trainer/train_results.json ]\n",
      "[2024-06-26 23:34:10,627: INFO: 378739507: Best Model found is : LinearRegression()]\n",
      "[2024-06-26 23:34:10,629: INFO: common: pickle object saved at artifacts\\model_trainer\\best_model.pkl]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config)\n",
    "    model_params = model_trainer.models_trainer(config.params, model_trainer_config.transformed_train_data_path,\n",
    "                                                model_trainer_config.transformed_test_data_path)\n",
    "except Exception as e:\n",
    "    raise e"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-27T06:34:10.638310200Z",
     "start_time": "2024-06-27T06:33:49.150284100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
